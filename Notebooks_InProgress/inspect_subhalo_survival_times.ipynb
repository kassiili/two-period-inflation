{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas for this notebook\n",
    "\n",
    "- try looking at evolution histories at, say, snapshot 126: is there a satellite that gets destroyed before snapshot 127? Could this work as an illustrative satellite?\n",
    "- Select 10 luminous (solid lines) and 10 dark (dashed lines)\n",
    "- Plot survival times in mass bins (v_max < 15 km/s, ...) and split each bar into luminous and dark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from astropy import units\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import my library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "apt_path = os.path.abspath(os.path.join('..', 'apostletools'))\n",
    "sys.path.append(apt_path)\n",
    "\n",
    "import simulation\n",
    "import simtrace\n",
    "import match_halo\n",
    "import dataset_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(simulation)\n",
    "importlib.reload(simtrace)\n",
    "importlib.reload(match_halo)\n",
    "importlib.reload(dataset_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution Histories of the Subhalos Present at $z=0$\n",
    "\n",
    "In this notebook, I inspect the origins of the subhalos that are satellites of the central galaxies at $z=0$, and also some isolated subhalos. I will look at their trajectories, and mass evolution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plain-LCDM-LR\n",
    "\n",
    "Set the envelope file path, and define the M31 and the MW at redshift $z=0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = os.path.abspath(os.path.join('..', 'test_tracing_inj'))\n",
    "sim= simulation.Simulation(\"V1_LR_fix\", env_path=env_path)\n",
    "\n",
    "m31_id_z0 = (1, 0)\n",
    "mw_id_z0 = (2, 0)\n",
    "snap_z0 = 127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Tracing\n",
    "\n",
    "Set the range of snapshots to be traced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_start = 100\n",
    "snap_stop = 128\n",
    "snap_ids = np.arange(snap_start, snap_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the simulations are not already linked:\n",
    "matcher = match_halo.SnapshotMatcher(n_link_ref=20, n_matches=1)\n",
    "mtree = simtrace.MergerTree(sim, matcher=matcher, branching=\"BackwardBranching\")\n",
    "mtree.build_tree(snap_start, snap_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Subhalo objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace subhalos and get the M31 and the MW Subhalo objects:\n",
    "sub_dict = sim.trace_subhalos(snap_start, snap_stop)\n",
    "\n",
    "m31 = sub_dict[snap_z0][\n",
    "    sim.get_snapshot(snap_z0).index_of_halo(m31_id_z0[0], m31_id_z0[1])\n",
    "]\n",
    "mw = sub_dict[snap_z0][\n",
    "    sim.get_snapshot(snap_z0).index_of_halo(mw_id_z0[0], mw_id_z0[1])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Retrieve the Datasets\n",
    "\n",
    "Read all datasets into dictionaries by snapshot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = {sid: z for sid, z in zip(\n",
    "    snap_ids, sim.get_attribute(\"Redshift\", \"Header\", snap_ids)\n",
    ")}\n",
    "\n",
    "# Get the datasets in a dictionary, with items for each snapshot data:\n",
    "mass = {sid: m * units.g.to(units.Msun) for sid, m in\n",
    "        sim.get_subhalos(snap_ids, \"Mass\").items()}\n",
    "vmax = {sid: vm[:, 0] * units.cm.to(units.km) for sid, vm in\n",
    "        sim.get_subhalos(snap_ids, \"Max_Vcirc\", h5_group=\"Extended\").items()}\n",
    "cop = {sid: c * units.cm.to(units.kpc) for sid, c in\n",
    "       sim.get_subhalos(snap_ids, \"CentreOfPotential\").items()}\n",
    "\n",
    "m31_dist = {sid: np.linalg.norm(d, axis=1) * units.cm.to(units.kpc)\n",
    "            for sid, d in m31.distance_to_self(snap_ids).items()}\n",
    "mw_dist = {sid: np.linalg.norm(d, axis=1) * units.cm.to(units.kpc)\n",
    "           for sid, d in mw.distance_to_self(snap_ids).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define masking arrays to select satellites of M31 and MW and random sample of isolated galaxies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get masking arrays for satellites (at z=0):\n",
    "mask_m31, mask_mw, mask_isol = dataset_comp.split_satellites_by_distance(\n",
    "    sim.get_snapshot(snap_z0), m31, mw, sat_r=300\n",
    ")\n",
    "\n",
    "# Randomly select ´n_isol´ isolated galaxies:\n",
    "n_isol = 30\n",
    "mask_rand = np.full(np.sum(mask_isol), False)\n",
    "mask_rand[:n_isol] = True\n",
    "np.random.shuffle(mask_rand)\n",
    "\n",
    "mask_rand_isol = np.full(mask_isol.size, False)\n",
    "mask_rand_isol[mask_isol] = mask_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the selections and write the dataset that are ready for plotting to a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the full datasets, read M31 satellite data and add to the data dictionary:\n",
    "data = {}\n",
    "\n",
    "m31_sats = sub_dict[snap_z0][mask_m31]\n",
    "data[\"M31_Satellites\"] = {\n",
    "    \"Snap_id\": [np.array(sat.get_indices())[1] for sat in m31_sats],\n",
    "    \"Redshift\": [np.array([redshift[sid] for _, sid in zip(*sat.get_indices())])\n",
    "                 for sat in m31_sats],\n",
    "    \"Mass\": [dataset_comp.subhalo_dataset_from_dict(sat, mass)[0] for sat in m31_sats],\n",
    "    \"Vmax\": [dataset_comp.subhalo_dataset_from_dict(sat, vmax)[0] for sat in m31_sats],\n",
    "    \"Distance\": [dataset_comp.subhalo_dataset_from_dict(sat, m31_dist)[0] for sat in m31_sats]\n",
    "}\n",
    "\n",
    "# ...Same for MW:\n",
    "mw_sats = sub_dict[snap_z0][mask_mw]\n",
    "data[\"MW_Satellites\"] = {\n",
    "    \"Snap_id\": [np.array(sat.get_indices())[1] for sat in mw_sats],\n",
    "    \"Redshift\": [np.array([redshift[sid] for _, sid in zip(*sat.get_indices())])\n",
    "                 for sat in mw_sats],\n",
    "    \"Mass\": [dataset_comp.subhalo_dataset_from_dict(sat, mass)[0] for sat in mw_sats],\n",
    "    \"Vmax\": [dataset_comp.subhalo_dataset_from_dict(sat, vmax)[0] for sat in mw_sats],\n",
    "    \"Distance\": [dataset_comp.subhalo_dataset_from_dict(sat, mw_dist)[0] for sat in mw_sats]\n",
    "}\n",
    "\n",
    "# ...Same for the randomly selected isolated galaxies:\n",
    "isol_subs = sub_dict[snap_z0][mask_rand_isol]\n",
    "data[\"Isolated\"] = {\n",
    "    \"Snap_id\": [np.array(sat.get_indices())[1] for sat in isol_subs],\n",
    "    \"Redshift\": [np.array([redshift[sid] for _, sid in zip(*sat.get_indices())])\n",
    "                 for sat in isol_subs],\n",
    "    \"Mass\": [dataset_comp.subhalo_dataset_from_dict(sat, mass)[0] for sat in isol_subs],\n",
    "    \"Vmax\": [dataset_comp.subhalo_dataset_from_dict(sat, vmax)[0] for sat in isol_subs],\n",
    "    \"MW_Distance\": [dataset_comp.subhalo_dataset_from_dict(sat, mw_dist)[0] for sat in isol_subs]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subhalo Survival Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_time = {sid: np.array([len(sub.indices) for sub in subs])\n",
    "             for sid, subs in sub_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the number of snapshots, through which each snapshot is traced, against its $v_\\mathrm{max}$. Below plot the counts of subhalos for each survival time. \n",
    "\n",
    "We see that, by far, most subhalos survive through the entire time range, through which we have done the linking. Only a small fraction is traced for less than 5 snapshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2)\n",
    "\n",
    "st = surv_time[snap_z0]\n",
    "st_unique, st_cnt = np.unique(st, return_counts=True)\n",
    "v = vmax[snap_z0]\n",
    "\n",
    "axes[0].scatter(st, v)\n",
    "axes[1].plot(st_unique, st_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the masses of the subhalos that survive longest vs. those that die shortly, more closely. I divide the subhalos into those that survive the whole linking period, those that survive through less than 3 snapshots, and all in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_prune = (v < 100)\n",
    "mask_long_surv = np.logical_and((st == max(st)), mask_prune)\n",
    "print(np.sum(mask_long_surv))\n",
    "mask_inter_surv = np.logical_and(np.logical_and((st > 3), (st < max(st))), mask_prune)\n",
    "print(np.sum(mask_inter_surv))\n",
    "mask_short_surv = np.logical_and((st <= 3), mask_prune)\n",
    "print(np.sum(mask_short_surv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are histograms for each of these categories (by  $v_\\mathrm{max}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_edges = np.linspace(10, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=3, sharey=True, sharex=True, figsize=(10,4))\n",
    "\n",
    "_ = axes[0].hist(v[mask_short_surv], bins=bin_edges, density=True)\n",
    "_ = axes[1].hist(v[mask_inter_surv], bins=bin_edges, density=True)\n",
    "_ = axes[2].hist(v[mask_long_surv], bins=bin_edges, density=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
