{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy import units\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import my library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "apt_path = os.path.abspath(os.path.join('..', 'apostletools'))\n",
    "sys.path.append(apt_path)\n",
    "\n",
    "import simulation\n",
    "import simtrace_redo\n",
    "import match_halo_redo\n",
    "import dataset_comp\n",
    "import subhalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(simulation)\n",
    "importlib.reload(simtrace_redo)\n",
    "importlib.reload(match_halo_redo)\n",
    "importlib.reload(dataset_comp)\n",
    "importlib.reload(subhalo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For computation time efficiency analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test match_halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = match_halo_redo.SnapshotMatcher(n_link_ref=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, study the low-resolution simulation. Create new, blank envelope files in the directory \"test_tracing\" (make sure that no envelope files exist in that directory before testing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_id = \"V1_MR_fix\"\n",
    "env_path = os.path.abspath(os.path.join('..', 'test_tracing_minmatch'))\n",
    "print(env_path)\n",
    "sim = simulation.Simulation(sim_id, env_path=env_path)\n",
    "sim.get_snap_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try matching two snapshots. Inspect the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Branching backward in time:\n",
    "snap_ref = sim.get_snapshot(126)\n",
    "snap_srch = sim.get_snapshot(127)\n",
    "%timeit matches_ref, matches_srch = matcher.match_snapshots(snap_ref, snap_srch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%lprun -f matcher.match_snapshots matcher.match_snapshots(snap_ref, snap_srch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%lprun -f matcher.is_a_match matcher.match_snapshots(snap_ref, snap_srch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_ref, matches_srch = matcher.match_snapshots(snap_ref, snap_srch)\n",
    "print(matches_ref.shape)\n",
    "print(matches_srch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ~5s matching time for a pair of snapshots and up to ~120 snapshots to match, the total runtime for tracing the entire LR simulation would be around 10 min. This seems acceptable.\n",
    "\n",
    "Of course, the question is: is this fast enough to trace a MR simulation? The most computing time is spent in the `np.interset1d` function calls, i.e. computing the intersections between the most bound particles between two subhalos. This function is called 468241 times, which means that 468241 pairs of subhalos are tried as matches. \n",
    "\n",
    "This is probably the most time efficient function for finding the intersections, i.e. finding out whether two subhalos match. Thus, the only way to speed up the `match_snapshots` function would be to decrease the number of matching trials. But this is also quite difficult to do: probably the most promising way would be to use spatial and kinematic information. \n",
    "\n",
    "Note that the number of matching trials, if every subhalo in snap_ref was tried with every subhalo in snap_srch, would be 1116 * 1125 = 1255500. So, by restring trials to subhalos within mass range of factor 3 and halting at the first match, we reduce the number of trials only by about 37 % (468241 / (1116 * 1125 = 0.373). Most subhalos are in the low-mass range. Also, the subhalos with the smallest mass are also rarely matched.\n",
    "\n",
    "\n",
    "Let\n",
    "> $n$ be the average number of subhalos in a snapshot, and \\\n",
    "> $k$ the average number of bound particles in a subhalo.\n",
    "\n",
    "The time complexity of `match_snapshots` is $\\mathcal{O}(n^2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the matches\n",
    "\n",
    "First, simply print the matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "gns_ref = snap_ref.get_subhalos('GroupNumber')\n",
    "sgns_ref = snap_ref.get_subhalos('SubGroupNumber')\n",
    "gns_srch = snap_srch.get_subhalos('GroupNumber')\n",
    "sgns_srch = snap_srch.get_subhalos('SubGroupNumber')\n",
    "\n",
    "for i, j in enumerate(matches_ref):\n",
    "    if j != matcher.no_match:\n",
    "        print(\"({}, {}) --> ({}, {})\".format(gns_ref[i], sgns_ref[i],\n",
    "                                             gns_srch[j], sgns_srch[j]))\n",
    "    else:\n",
    "        print(\"({}, {}) NO MATCH\".format(gns_ref[i], sgns_ref[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most massive central halos are always matched. Most of the subhalos of M31 and MW are matched. \n",
    "\n",
    "Note, that subhalos of a central remain subhalos of the same central, even when the group number changes:\n",
    "> (10.0, 0.0) --> (11.0, 0.0) \\\n",
    "> (10.0, 1.0) --> (11.0, 1.0) \\\n",
    "> (10.0, 2.0) --> (11.0, 2.0) \\\n",
    "> (11.0, 0.0) --> (9.0, 0.0) \\\n",
    "> (11.0, 1.0) --> (9.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "WRITE A DOCUMENT ON THIS TESTING PROCESS!\n",
    "\n",
    "What do you see in the above output? What is note-worthy? What confirms you that the program is working as intended? ...that there are no bugs? What is suspicious? Which relevant questions cannot be answered based on the above? What next?\n",
    "\n",
    "Document the step-by-step process, by which you become convinced that everything works. Then, reflect: is the process thorough and reliable? Is the program well-structured; too complicated and difficult to test, or easy to understand?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No two subhalos in snap_ref are matched with the same subhalo in snap_srch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, cnts = np.unique(matches_ref, return_counts=True)\n",
    "print(\"Total number of matches: {}\".format(vals.size))\n",
    "print(\"Subhalos in snap_srch that are matched more than ones:\")\n",
    "print(\"Indices: {}\".format(vals[cnts > 1]))\n",
    "print(\"Counts: {}\".format(cnts[cnts > 1]))\n",
    "\n",
    "print(\"Indices in ref: {}\".format([list(np.arange(matches_ref.size)[matches_ref == v]) \n",
    "                                   for v in vals[cnts > 1] if v != matcher.no_match]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(matches_srch[:,1] != matcher.no_match))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merger Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_start = 101\n",
    "snap_stop = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.get_snapshot(snap_start).group_data.fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtree = simtrace_redo.MergerTree(sim, branching=\"BackwardBranching\")\n",
    "%lprun -f mtree.build_tree_with_back_branch mtree.build_tree(snap_start, snap_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, no mergers found between any of the pairs of snapshots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "snap_stop=101\n",
    "for sid in range(127, snap_stop, -1):\n",
    "    snap = sim.get_snapshot(sid)\n",
    "    prog = snap.get_subhalos('Progenitors', mtree.h5_group)\n",
    "#     print(prog.shape)\n",
    "    mask_merger = np.logical_or(prog[:,1] != mtree.no_match, \n",
    "                                prog[:,2] != mtree.no_match)\n",
    "    print(sid, np.sum(mask_merger))\n",
    "    print(np.size(prog, axis=0), np.sum(prog[:,0] != mtree.no_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "snap_stop=101\n",
    "for sid in range(snap_stop, 127):\n",
    "    snap = sim.get_snapshot(sid)\n",
    "    desc = snap.get_subhalos('Descendants', mtree.h5_group)\n",
    "    vals, cnts = np.unique(desc, return_counts=True)\n",
    "    mask_merger = np.logical_and(vals != mtree.no_match, cnts > 1)\n",
    "    print(sid, np.sum(mask_merger))\n",
    "    print(np.size(desc), np.sum(desc != mtree.no_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = 126\n",
    "snap = sim.get_snapshot(sid)\n",
    "desc = snap.get_subhalos('Descendants', mtree.h5_group)\n",
    "prog = snap.get_subhalos('Progenitors', mtree.h5_group)\n",
    "mask_shadow = np.logical_and(prog[:,0] == mtree.no_match, desc == mtree.no_match)\n",
    "\n",
    "masks_sat, mask_isol = dataset_comp.split_satellites_by_group_number(\n",
    "    snap, (1,0), (2,0))\n",
    "mask_sat = np.logical_or.reduce(masks_sat)\n",
    "\n",
    "mass = snap.get_subhalos('Mass') * units.g.to(units.Msun)\n",
    "m = np.sort(mass)\n",
    "m_s = np.sort(mass[mask_shadow])\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].set_xscale('log')\n",
    "ax[1].set_xscale('log')\n",
    "\n",
    "m = mass[mask_sat]\n",
    "ax[0].plot(np.sort(m), np.arange(m.size))\n",
    "m = mass[np.logical_and(mask_sat, mask_shadow)]\n",
    "ax[0].plot(np.sort(m), np.arange(m.size))\n",
    "\n",
    "m = mass[mask_isol]\n",
    "ax[1].plot(np.sort(m), np.arange(m.size))\n",
    "m = mass[np.logical_and(mask_isol, mask_shadow)]\n",
    "ax[1].plot(np.sort(m), np.arange(m.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
